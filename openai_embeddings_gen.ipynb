{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOPons9eRFKzHJ3v12HN1eA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michaelwnau/ml-data-ops-notebooks/blob/main/openai_embeddings_gen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "nWSZieWsX1xJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will be used to create embeddings from text files."
      ],
      "metadata": {
        "id": "s-FtF6kT4m_N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV_rSQip4hhT",
        "outputId": "83555690-f7ff-4c3c-f837-01837ade4877"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "This notebook uses Google Drive as the document repository because it is relatively inexpensive\n",
        "to store unstructured text files this way. Other uses might see Notion databases used.\n",
        "\n",
        "'''\n",
        "\n",
        "# 1. Set up Google Colab to work with Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "This version of the notebook is going to have more libraries than immediately necessary\n",
        "for embeddings, in case we want to add other functionality.\n",
        "\n",
        "'''\n",
        "\n",
        "# 2. Install necessary libraries\n",
        "\n",
        "\n",
        "\n",
        "# 2. Install and import necessary libraries.\n",
        "\n",
        "!pip install openai\n",
        "!python -m spacy download en_core_web_sm\n",
        "\n",
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "import spacy as sp\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "\n",
        "# Load the English model. Note that this can be changed with models for other languages. Visit https://spacy.io/usage/models\n",
        "nlp = sp.load('en_core_web_sm')\n"
      ],
      "metadata": {
        "id": "OUpJDdGnWRm5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07b29c05-78a9-4228-9e6f-de6caa95df98"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "2023-08-22 19:38:47.889424: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-22 19:38:49.132671: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Collecting en-core-web-sm==3.6.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.6.0/en_core_web_sm-3.6.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.6.0) (3.6.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.66.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (1.23.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.2.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.5.0)\n",
            "Requirement already satisfied: pydantic-core==2.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (0.1.1)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->en-core-web-sm==3.6.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Hardcode the path to the text file in the Google Drive\n",
        "\n",
        "file_path = \"/content/drive/MyDrive/corpus-zeta/2023/oit-videos-bios/brad-houston-2023-05-13-apid-oit.txt\"\n",
        "\n",
        "# Read the content of the file into the `lines` variable\n",
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "# Print the first 5 lines of the file\n",
        "print(lines[:5])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1jw5Tq1Yjye",
        "outputId": "43dae111-2846-4503-a6b7-14d351a3506c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[\"Analysis and Integrity and at the Regional Offices in Atlanta, Georgia, and Providence, Rhode Island.  He is also an Operation Desert Storm, veteran of the United States Army. Please join me in welcoming Mr. Brad Houston.  Good morning. Appreciate your. I appreciate the opportunity to talk to you all this morning.  I'm pretty excited about the things we're doing and I and happy to share them and hopefully help you find ways  you can better engage with VA in our in our journey for the future.  So to get to the next slide, please. So first, just let me talk a little bit about what the business integration  and outcome service is. Our job is to create the vision,  the co-create, the vision on what we can do with our business partners. We do this by understanding the business,  understanding what it can do, and trying to link the two together. We've been working  really hard over the last six months to create very clear business outcome.  The outcomes to capture the outcomes business needs from I.A., to capture the metrics they will use to measure  whether we deliver it successfully or not. And then to map those outcomes to the various lines and Services Alliance provides.  We're doing this, as I say, collaboratively, working with both Orient and business to make that we really get a clear vision, a common  outcome that everyone buys into for the future. Next slide, please.  Everything's better with a picture. And so just a little picture of how works.  We really we really exist to make sure that the NCA, VBA, VHA, the Board of Veterans Appeals, all the staff offices  are able to put pen to paper on what they want from I.T. And they shouldn't have to do it by saying,  well, I would like product engineering to give me this tool. I would like end user operations to give me this.  They should be able to say as a business partner what they want to accomplish. And we and bio serves the translate that into i.t.  Make sure that the right pieces go to the right places in i.t and that we deliver those products that matter most.  And a little bit I'll talk to you about our one analyst, which we're very excited about, but that one day analyst starts with creating a clear vision  that the business partner can say that they subscribe to so that they support what our alliance is doing. Next slide.  To accomplish this, they've got a leadership team that's shown on the board here  looking at the list and names of attendees. Many of you probably some of these folks Lloyd Thrower, Grace Lanier, George Washington,  Rebekah Paul Tibbets and Hal Griffin are the leadership team with him. BIOS who work directly with our business partners  to advocate for what they need. But these folks are keenly aware of what the the art of the possible is in L.A.  and they spend probably more time with the business partner than they do with I.T. Saying, what is it you're trying to do and how can we help you get there?  You can see on here the alignment of each of these, but each of these senior leaders with their or with their business partner organization and providing all of this  because they all know that they're there. Their job in understanding the art of the possible is not only  what A.E. does today, but also what industry is that we're maybe not taking advantage of.  And I know that that probably means most of them are going to get emails and phone calls and, hey, can we talk?  And that's perfect because we're trying to make sure that we bring the the best technology opportunities available to VA's business,  business elements and the veterans. Next slide, please.  Each of those leaders has a team underneath them that has a staff that has four key roles.  We have we deliberately from from our business partners and from outside to bring in business experts,  to bring in folks who speak business that maybe not necessarily systems, but absolutely business on what they're trying to accomplish and what it means.  We deliberately staff in partnership with at least a couple of your contract companies  to create a vision for that future. What are you where are we going and what are we doing next?  This vision also includes increasingly includes how are we doing this in a quote,  coherent, collaborative manner across our city. So we're not continuing to build, you know, titanium cylinders of excellence.  Earlier One of you had a question about what are we doing about tech That is outcome and visions expert also is the one who advocates  for the for with the business partner to get them and get them engaged and in  that is in the discussion and planning around retirement of older systems.  Most of you probably know it's super easy to deploy a new system that does 80% of that old systems,  but until you get 100%, that old system still sticks around. And that last few use cases are what is super difficult to get folks to  engage in and actually work off work off the backlog to retire this outcomes expert.  And each team is responsible for making sure we do that. And as with any major effort,  you've got to have somebody who understands money. I want to be super clear. BIOS is not it's Budget office.  We've got a cfo, we've got an i.t. Budget i.t budget and finance staff that does a great job.  These folks aren't aren't in any way trying to do that work. What they're trying to do is make sure that we've got well,  we've got the business vision and the future vision for i.t systems that we have the necessary funds on the budget  or if we don't, that we know where that gap is. And sometimes are also working on trying to estimate what the cost of these great ideas are.  So this is not a CFO function. This is just making sure that we've got the money to do the things we say we want to do.  And then finally, within each team and somebody who's an expert in I.T., well, maybe not  an expert like like Tim, who I just saw pop up on on video on my screen.  But at least they know if you push this button, this is the thing that's going to happen on the other side. And They know who to call and who to ask  and who pushed for questions and clarifications when there's issues. This this last role is also the one where we track systems outages  and security issues and make sure that we're adequately addressing those with our business partner and within I.T.  and making sure that our business partner understands the need for that investment in those systems.  Next slide, please. So how do we do this?  Well, from a simple diagrams perspective, our business partners figure out what they need.  They usually have an idea of exactly how they want it delivered, using exactly what software.  And we try and take their vision and their very specific software that they maybe saw at a trade show  and then get them to come up just a little bit in altitude and just clearly say the outcomes they want.  What is their vision and outcomes? Don't tie their vision and outcomes to a specific product or something you saw somewhere else, but to a specific metric.  What is it you're trying to accomplish? And then we work with our I.T delivery partners  to figure out how can we deliver that in the most effective fashion and then focus in the in its product engineering,  software, product management, Chief Technology Officer, End user operations,  All of those folks actually deliver it. And I just would say that even though this shows it's very linear arrows from left to right, it's not anywhere near that clean and neat.  We're routinely learning things as as as our delivery partners are delivery  organizations that i.t deliver things we're continually learning about, things that we need to get feedback from on our business partner  or things that may change their vision. And so this is an iterative process where the folks I showed you earlier  are on a daily basis working with it and our business partners to make sure we've got their vision,  their long term vision and outcomes, the metrics to do it, and then we're working towards them.  Next slide. Earlier I mentioned the one to analyst,  and for those of you who haven't heard of a when to enlist, that's a priority list from our most important priority to our list  for the very first time in the last year, I worked with our business partners to have a comprehensive  one two endless from top to bottom across all of VA. That was that's a high watermark us and one we intend to sustain  because previously we had it was super easy to come up with a one. The analysts in each operating space  you need have the veterans experience office who wants an online it to improve the online application.  You've got the national cemeteries who wants to do pre needs registration the Board of Veterans appeals who wants to handle veterans appeals.  However, those priorities are different from one business partner to the next.  And so the delivery arms are frequently  one of them is working aveo's highest priority and with very little additional effort,  they can also accomplish NCA's priority. Since it wasn't on their list, they weren't tracking it.  And so we've created a one to enlist top to bottom of everything that it's been asked to work on and what the what the priority is  That's important for the delivery. The delivery I mentioned earlier, but it's also super important for how we  how we work with Congress and other stakeholders where we can show them the unmet demand in systems and show them why  a robust amount of funding for I.T. systems development, modernization, enhancement,  even retirements is important because they can see that list of unmet demands in servicing veterans that we haven't achieved yet.  So this has been a tremendous accomplishment. It's something that we we work on almost every day.  And we've and we and we've worked with, as I said earlier, with our business partners, to do it so that our business partners clearly understand exactly  where projects they may be interested in fit into VA's overall prioritization.  So you get the next slide, please let me bounce back up one, because I'm getting back into  and now I'm getting into a little more detail and I want to wait to do that. So why we want the that must be important to you?  Two reasons. One, if our one day analyst, our prioritization  has something you're working on that's pretty far down the list, then you all would understand how likely is it  that we're going to get funded to do that work this year? It's also important to you in that  many times our business partners are unable to clearly state  or clearly defend the business outcome. They're going to accomplish with our with their new priority.  Our team works with them to try and get clear outcomes for what they're trying to do.  But if you're working with a business partner and their or business partner reaches out to you about, hey,  we'd like to, you know, we're interested in this software you offer because we think it will make things just super cool.  The more you can help then change super cool into this outcome for a veteran or this outcome for a VA  will help them prioritize their work better. Just like with anything, when you're looking at different priorities,  understanding clearly the outcome, you'll get from one of them makes it much more likely that that will be the task  you pick up and works next, as opposed to something that says, you know, we're going to we're going to do good  and make everybody feel happy and possibly give everyone double stuffed Oreos.  So this is it's a knowledge understanding of this one. To enlist in this prioritization is important to both VA and industry  because the way to get higher on the one down list is to be able to demonstrate a greater impact  to the VA, to our mission and to veterans. When I was talking earlier about cybersecurity  and the cost of incidents, you know, because the cost of those incidents  can be so catastrophic, those projects tend to score very highly on the one endless  because they're able to create that clear that, clear impact statement. And so  this list is important to you or knowledge that there is this list is important to you because as you're working with business partners  in your business development or as they're reaching out and trying to understand what your tools can do,  the more you can steer them to what are your metrics and what are your outcomes, the more likely it is that work will get accomplished.  Their work will be prioritized and be accomplished in any given year.  Okay, The next couple of slides are the contracts that BIOS uses to accomplish this work.  We have a couple, we have six. We have four slides of contracts  with with amounts. And what they do rather than go through those  those line by line, I'd rather just talk about what we accomplished with those contracts.  We use those we use contract support to do a couple of really important tasks. One of them is creating that business vision  and creating those metrics or co-creating them. It is sitting down with a business partner  and mapping out all the systems in that business partner space, saying what those business systems do and understanding what which business  metrics they want to move the most. Then identifying those business metrics, those business,  what levers in the systems can move those business metrics and prioritizing that work.  We use it. We use vendor support to do this because in many cases, the ability to create that system  for such a complex space is something that the BIOS staff is just too small to accomplish right now.  And while we're game that skills absolutely using, we're actually absolutely using industry to help us put that vision to paper.  There's a temptation for that kind of work to just keep going and going and going. Everyone loves a great diagram.  The challenge for us is not continuing to create that great diagrams. However, it is to turn those diagrams into actions.  And that takes us to our second contract main contract space, which is service and support.  That's taking those great diagrams and putting the work that needs to be accomplished in those diagrams, in the project plans,  putting it into clear identifying clear milestones and saying what happens next.  And so on these pages, which I believe the attachments went out with the meeting,  you can see the details on on that on the contracts they ammo has  and you can see where we absolutely depend on industry to help us bring the skills to shape the future vision for what we're doing in IT.  System space. So maybe I  either miss measured my time or I just had too much caffeine this morning and talk really fast.  However, that's the end of my slide, so I'm happy to take any questions folks may have.  How can I make this time useful for you? Thank you, Mr.  Houston. If it's okay with you, we're going to take these questions that have come in and collect them and then put them to the side for you to answer during the roundtable.  It's absolutely okay with me. I'm I'm happy to answer questions whenever. And, you know,  I also did see Tim come on the video and I immediately thought I need to get out of Tim's way  because he's got a lot of good things to share. So I'm happy to wait for the roundtable. Thank you so much for joining us, Mr. Houston. And your staff.  Our next speaker is Mr. Timothy McCUTCHEON. Mr. McCUTCHEON serves as the acting executive\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI API Key\n",
        "Use"
      ],
      "metadata": {
        "id": "093fbYIdEXyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Secrets\n",
        "openai.api_key = \" \"\n"
      ],
      "metadata": {
        "id": "ZCSXhjE-aF2P"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Chunking - For the time being, it is best practices to break text into separate sections. This allows us to monitor the embeddings.\n",
        "\n",
        "# Define a function to chunk the text\n",
        "def chunk_text_spacy(text, max_tokens=2000):\n",
        "    '''\n",
        "    Splits the text into chunks that have a token length that is set by 'max_tokens'. This should be adjusted based on\n",
        "    documentation at https://platform.openai.com/docs/guides/gpt-best-practices/strategy-use-external-tools\n",
        "    '''\n",
        "    doc = nlp(text)\n",
        "    chunks = []\n",
        "    current_chunk = []\n",
        "\n",
        "    for token in doc:\n",
        "        current_chunk.append(token.text)  # Use token.text to get the string representation\n",
        "        # If the current chunk is nearing the token limit, join it and start a new chunk\n",
        "        if len(current_chunk) >= max_tokens:\n",
        "            chunks.append(' '.join(current_chunk))\n",
        "            current_chunk = []\n",
        "\n",
        "    # Add the last chunk if it is not empty\n",
        "    if current_chunk:\n",
        "        chunks.append(' '.join(current_chunk))\n",
        "\n",
        "    return chunks\n",
        "\n",
        "# Chunk the file content\n",
        "all_chunks = [chunk for line in lines for chunk in chunk_text_spacy(line)]  # Use chunk_text, not chunk_text_spacy\n",
        "\n",
        "print(f\"Total number of chunks: {len(all_chunks)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0W0pM3fGaNgx",
        "outputId": "7c5b1856-4e4b-4bb8-9aba-0416624431ee"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of chunks: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5."
      ],
      "metadata": {
        "id": "327trfV94v2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 6. Generate embeddings using OpenAI API for EACH chunk\n",
        "\n",
        "embeddings = [generate_embeddings(chunk) for chunk in all_chunks]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "2y8PsVCk4EAo",
        "outputId": "d6850397-435e-4bce-a5d1-79f806d2adb2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-c6bf43b7176c>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 6. Generate embeddings using OpenAI API for EACH chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_chunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-c6bf43b7176c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 6. Generate embeddings using OpenAI API for EACH chunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgenerate_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_chunks\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'generate_embeddings' is not defined"
          ]
        }
      ]
    }
  ]
}